#!/bin/bash -eu

#   bashreduce: mapreduce in bash
# 
#   erik@fawx.com
#   dakusui@gmail.com

usage() {
  local prog="`basename $1`"
  echo "Usage: $prog [-m host1 [host2...]] [-c column] [-r userfunc] [-i input] [-o output]"
  echo "       $prog -h for help."
  exit 2
}

showhelp() {
  echo "Usage: `basename $1`: [-m host1 [host2...]] [-c column] [-r userfunc] [-i input] [-o output]"
  echo   "bashreduce.  Map an input file to many hosts, sort/reduce, merge"
  echo   "  -m: hosts to use, can repeat hosts for multiple cores"
  echo   "      default hosts from ~/.br.hosts or /etc/br.hosts"
  echo   "  -p: base port, default = 8192"
  echo   "  -M: mode ('map', 'reduce', 'compat'), default = 'compat'"
  echo   "  -I: interpreter. ignored if 'compat' mode is used, default = 'sh -c'"
  echo   "  -j: job index, default = 0"
  echo   "  -c: column to partition, default = 1 (1-based)"
  echo   "  -i: input file, default = stdin"
  echo   "  -r: userfunc function, default = identity"
  echo   "  -o: output file, default = stdout"
  echo   "  -t: tmp dir to use, default = /tmp"
  echo   "  -l: error log file, default = /dev/null"
  echo   "  -S: memory to use for sort, default = 256M"
  echo   "  -s: extra parameter(s) given to 'sort' command, default =  "
  echo   "  -O: perform sort on output, ignored in 'compat' mode., default = yes"
  echo   "  -h: this help message"
  exit 2
} 


# out
#   jobid    "${OPTARG:-$(uuid)}"
#   jobpath  "${tmp_dir:-/tmp}/br_job_${jobid}}"
#   nodepath "${tmp_dir:-/tmp}/br_node_${jobid}}"
# local
bashr_paramcheck() {
    ${LC_ALL:=""}
    local brhostsfile="/etc/br.hosts"
    [ -e "$HOME/.br.hosts" ] && brhostsfile="$HOME/.br.hosts"
    base_port=8192
    job_idx=0
    mode='compat'
    interpreter='sh -c'
    hosts=
    mapcolumn=1
    userfunc=
    input=
    output=
    tmp_dir=/tmp
    sort_mem=256M
    sort_opt=
    sort_on_out=yes
    errlog='/dev/null'

    while getopts "m:p:j:M:I:c:r:i:o:t:S:s:O:l:h" name; do
	case $name in
	    m)  hosts=$OPTARG;;
	    p)  baseport=$OPTARG;;
	    j)  job_idx=$OPTARG;;
	    M)  mode=$OPTARG;;
            I)  interpreter=$OPTARG;;
	    c)  mapcolumn=$OPTARG;;
	    r)  userfunc=$OPTARG;;
	    i)  input=$OPTARG;;
	    o)  output=$OPTARG;;
	    t)  tmp_dir=$OPTARG;;
	    S)  sort_mem=$OPTARG;;
	    s)  sort_opt=$OPTARG;;
            O)  sort_on_out=$OPTARG;;
	    l)  errlog=$OPTARG;;
	    h)  showhelp $0;;
	    [?])  usage $0;;
	esac
    done 
    if [ -z "$hosts" ]; then
	if [ -e "$brhostsfile" ]; then
	    hosts=`cat "$brhostsfile"`
	fi
    fi
    # check if 'hosts' is set.
    hosts=${hosts:?"`basename $0`: must specify hosts with -m or provide ~/.br.hosts or /etc/br.hosts"}
    case "$mode" in
	compat|map|reduce)
            ;;
        debug)
            ;;
	*)
            echo "`basename $0`: unknown mode is specified. ($mode)"
            usage $0
    esac
    jobid=${jobid:-"`uuidgen`"}

    # okay let's get started!  first we need a name for our job
    jobpath="$tmp_dir/br_job_$jobid"
    nodepath="$tmp_dir/br_node_$jobid"
}

# * in
#   
# * out
#   sorter
#   userfunc
# * tmp (local)
#   
bashr_init() {
    sorter="LC_ALL='$LC_ALL' sort -S$sort_mem $sort_opt -T$tmp_dir -k$mapcolumn,$mapcolumn 2>/dev/null"
    usercode=
    case $mode in 
	map)
            if [[ -z $userfunc ]]; then
 		echo "`basename $0`: $mode is specified. must specify userfunc with -r"
		usage $1
            fi
	    usercode='{
                cmd=sprintf("%s %c%s%c", ENVIRON["INTERPRETER"], 39, ENVIRON["USERFUNC"], 39);
                print | cmd; 
            }'
            ;;
	reduce)
            if [[ -z $userfunc ]]; then
 		echo "`basename $0`: $mode is specified. must specify userfunc with -r"
		usage $1
            fi
	    usercode='BEGIN {
                cmd=sprintf("%s %c%s%c", ENVIRON["INTERPRETER"], 39, ENVIRON["USERFUNC"], 39);
                firsttime=1;
                key="";
                keyindex=ENVIRON["MAPCOLUMN"];
            }
            {
                if (key!=$keyindex) {
                  if (firstTime!=1) {
                      close(cmd); 
                  }
                }
                print | cmd;
                fisttime=0;
                key=$keyindex;
            }
            END {
                if (firsttime==0) {
                    close(cmd);
                }
            }'
            ;;
	compat)
	    if [ -z "$userfunc" ]; then
	    # if we have a userfunc, add the pipe explicitly
		usercode="| $interpreter '$userfunc' 2> $errlog"
	    fi
    esac
}

bashr_debug() {
    echo "mode:"  ${mode//\n/ }
    echo "hosts:" ${hosts//\n/ }
}

# Executes a map/reduce/comat task
# 
# variables:
# * read
#   hosts
#   mode
#   mapcolumn
#   userfunc
#   sort_opt
#   sorter
#   jobpath
#   nodepath 
# * write
#   (none)
# * local
#   host
#   pid
#   envvars
#   port_in
#   port_out
#   host_idx
#   out_files
#   in_files
#   input
bashr_executetask() {
    # now, for each host, set up in and out fifos (and a netcat for each), and ssh to each host to set up workers listening on netcat
    num_hosts=$(($(echo "$hosts" | wc -w)))
    port_in=$(($base_port + $num_hosts * $job_idx * 2))
    port_out=$(($port_in + 1))
    mkdir -p $jobpath/{in,out}

    local host_idx=0
    local out_files=
    local in_files=
    
    for host in $hosts; do
        # our named pipes
	mkfifo $jobpath/{in,out}/$host_idx
        # lets get the pid of our listener
	ssh -n $host "mkdir -p $nodepath"
	local pid=$(ssh -n $host "nc -l -p $port_out >$nodepath/in_$host_idx 2>/dev/null </dev/null & jobs -l" | awk {'print $2'})
	local envvars="MAPCOLUMN=$mapcolumn INTERPRETER='$interpreter' USERFUNC='$userfunc' HOST_IDX='$host_idx'"
	case "$mode" in
            map|reduce)
		ssh $host -n \
		    "tail -s0.1 -f --pid=$pid $nodepath/in_$host_idx 2>/dev/null </dev/null \
                | $envvars awk '$usercode' | $sorter \
                | nc -q0 -l -p $port_in >&/dev/null &"
		;;
            compat|*)
		ssh $host -n \
		    "tail -s0.1 -f --pid=$pid $nodepath/in_$host_idx 2>/dev/null </dev/null \
                | $sorter $usercode \
                | nc -q0 -l -p $port_in >&/dev/null &"
		;;
	esac
        # our local forwarders
	nc $host $port_in >$jobpath/in/$host_idx &
	nc -q0 $host $port_out <$jobpath/out/$host_idx &
        # our vars
	out_files="$out_files $jobpath/out/$host_idx"
	in_files="$in_files $jobpath/in/$host_idx"
	port_in=$(($port_in + 2))
	port_out=$(($port_in + 1))
	host_idx=$(($host_idx + 1))
    done
    
    ####    
    # okay, time to map
    if which brp >/dev/null; then
	eval "${input:+pv $input |} brp - $(($mapcolumn - 1)) $out_files"
    else
    ####    
    # use awk if we don't have brp
    # we're taking advantage of a special property that awk leaves its file handles open until its done
    # i think this is universal
    # we're also sending a zero length string to all the handles at the end, in case some pipe got no love
	eval "${input:+pv $input |} awk '{
            srand(\$$mapcolumn);
            print \$0 >>\"$jobpath/out/\"int(rand() * $host_idx);
        }
        END {
            for (i = 0; i != $host_idx; ++i)
            printf \"\" >>\"$jobpath/out/\"i;
        }'"
    fi

    ####    
    # save it somewhere
    # use sort -m. 
    # (abolished brm to simplify the software since i couldn't convince myself there is a big performance gain)
    # sort -m creates tmp files if too many input files are specified
    # brm doesn't do this
    if [ $sort_on_out == "yes" ] ; then
	eval "sort $sort_opt -k$mapcolumn,$mapcolumn -m $in_files ${output:+| pv >$output}"
    else
	eval "cat $in_files ${output:+| pv >$output}"
    fi
    
    ####    
    # finally, clean up after ourselves
    rm -rf $jobpath
    for host in $hosts; do
	ssh $host "rm -rf $nodepath"
    done
    
    ####    
    # TODO: is there a safe way to kill subprocesses upon fail?
    # this seems to work: /bin/kill -- -$$
}

bashr_paramcheck "$@"
bashr_init

if [ $mode == "debug" ]; then
    bashr_debug;
else
    bashr_executetask;
fi
