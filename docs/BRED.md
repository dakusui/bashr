# bred : bashreduce enhanced.

```bred``` is an enhanced version of Erik Frey's ```bashreduce```.

## About [```bashreduce```](https://github.com/erikfrey/bashreduce)
```bashreduce``` is a shell script created by erikfrey that lets you apply your favorite unix tools in a mapreduce fashion
across multiple machines/cores.  There's no installation, administration, or distributed filesystem.

## About ```bred```
```bred``` is an enhanced version of ```bashreduce```.
Same as ```bashreduce```, you'll only need:

* "[bred](http://github.com/dakusui/bred/blob/master/bred)": somewhere handy in your path
* vanilla unix tools: sort, awk, ssh, netcat, pv
* password-less ssh to each machine you plan to use

Followings are the enhancements implemented in ```bred```

* Created 'map' and 'reduce' behaviour modes, which allow you to perform
  tasks more normal mapreduce way. The behavior Erik Frey created is now
  called 'compat' and it is still a default.
* It searches for vacant ports automatically.
* Made it possible to specify base port.
* Added 'sort_opt' option to be able to make sort commands use it. This is
  useful e.g., when you want to sort the output by a numeric field. Use "-s '-n'"
* User code's stderrs are now output to files. Now debugging became much easier.
* Bundled ```br-test.sh```. By running this, you can check your machine is capable of
  running ```bred``` or ```xbred```
* Reorganized internal structure.

And one more difference from ```bashreduce``` is

* ```bred``` doesn't have ```brm```: I gave up making it consistent with 'sort -m'.

# Examples
## Distributed indexing

You can perform distributed indexing by one-liner with ```bred```.
Suppose you have only several ```localhost```'s and you'll run

```bash
find $(pwd) -type f -name '*.md' |nl -w 1 -s ' ' -b a|tee docid.dat |pv |bred -c 1 -s 3 -S1G -M map -I 'awk -f' -r '{
  for (l=1; (getline line < $2) > 0; l++) {
     gsub(/([[:punct:]]|[[:blank:]])+/, " ", line);
     n=split(line,cols," ");
     for (i = 1; i <= n; i++) { print $1, l, cols[i]; };
  }
}' |tee terms.dat |pv |bred -c 3 -s 1 -O no -M reduce -S1G -I 'awk -f' -r 'BEGIN { p=""; key="";} {
    if (key == "") key=$3;
    p=p " " $1 "," $2
} END { print "" key " " p; }' -o index.dat
```

* NOTE) trying ```find . -type f -name ...``` will generate no output. Because awk doesn't read a file whose name is like
  ```./hello.txt``` since it doesn't expand '.' or '~' to their full-path representations.

The command line above indexes all the '*.md' files under current directly.
A document id file and an inverted index will be generated as ```docid.dat``` and ```index.dat``` and they will look like below

* docid.dat
```

     6  /home/dakusui/workspace/symfonion/src/test/java/com/github/dakusui/symfonion/InvalidJsonErrorTest.java
     7  /home/dakusui/workspace/symfonion/src/test/java/com/github/dakusui/symfonion/core/FractionTest.java
     8  /home/dakusui/workspace/symfonion/src/test/java/com/github/dakusui/symfonion/InvalidDataErrorTest.java
     9  /home/dakusui/workspace/symfonion/src/test/java/com/github/dakusui/symfonion/ErrorTest.java
```

The first column of ```docid.dat``` is ID of each document and the second is the file's absolute location.

* index.dat
```

    planes  18,166 18,248 18,303 23,269 23,293
    SpritePlane  18,134 18,299 18,305 18,306 24,34 29,15 29,18
    QuitMu64  18,350 18,354 18,368 18,373
    setProperty  18,379 18,380 18,381 18,382
    Auto  16,156 16,169 19,134 25,52 25,55 25,58 25,61 25,64 25,67 25,70 41,111
    generated  16,156 16,169 19,134 25,52 25,55 25,58 25,61 25,64 25,67 25,70 41,111
    enabled  19,16 19,47 19,51
    VideoEngine  20,22 20,24 20,25 48,12 48,19 48,26
```

This file is the inverted index generated by your mapreduce process.
The words in the first column are indexed terms. The rest are positions where the term is found in the traversed document set.
Each element in a line is a comma separated string whose left part is document id, defined in ```docid.txt```, and the right side
is the line number where the term was found in the file.

If you prefer a script file, you can find it [here](examples/indexer.sh).

### Making it faster

The user code script you provide is executed by ```bred``` every time it finds a new key during reduce operation.
And the user code is executed as external command using the interpreter you specify by '-I' option.
Please be careful, you need to specify a command which interprets a file, not a string since ```bred``` internally 
generates temporary file to be executed for your job. For shell scripts, it will be 'sh' (not 'sh -c') and 
for awk scripts it will be 'awk -f' (not 'awk').

If there are a lot of keys to be passed to the reduce function, command execution overhead damages the performance severely.

```bred``` provides another behavior mode called ```awk-native```. You can set this string to '-I' option and awk code string
which defines three functions: ```bredBeginReduce(key_idx)```, ```bredReduceReduce(key_idx)```, and ``````bredEndReduce()```.
When ```bred``` finds a new key, it first calls ```bredEndReduce``` for the previous key and the it calls ```bredBeginReduce```
for the new key. And for each line ```bredBeginReduce``` will be called.

A short experiment shows that there would be 3 times performance gain when I indexed all texts Project Gutenberg as of 2003 (400MB).

The example is found [here](examples/indexer2.sh).

Signatures of those 'hook' functions called by ```bred``` are floating right now. You might need to calibrate them to
make it work in future when you start using one of future versions of ```bred```.

### But it's not 'distributed'
No, it's not. You need another couple of steps to make it distributed.

1. Include remote hosts you want to distribute indexing task to in br.hosts file.
2. Mount the shared file system (NFS, CIFS, sshfs, etc) at the same mount point among all the host referred in br.hosts file.

Then run the script on the mounted FS. 
Important point is, if a file name is given as ```$2```,

```
  for (l=1; (getline line < $2) > 0; l++) {
```
this code, which can be executed on any hosts in br.hosts, can always open the same file.

## poor man's DFS
I have implemented a poor man's DFS for ```bred```.
It can create, write, and read distributed files. Its ancestor ```br``` couldn't use this feature if the same host name is repeated in its configuration, but ```bred``` can do it.

### Limitations
Don't forget it's a poor man's one.

+ It can only store text files.
+ No redundancy.
+ Directory listing isn't supported yet.

### Preparation
At first, you need to source (import) necessary environment variables, functions, etc.
Please do this on your shell.

```
    . /usr/local/bin/bredfs
```


### Creating a file
Creating (initializing) a file can be done by following command line.

```
    STORE=/path/to/store bredfs init
```

, where ```/path/to/store``` is a path to the file.
By this, a file ```{fsdir}/{host index}/path/to/store``` will be created on each host.
```fsdir``` is a value configured in the configuration file (```bred.conf``` see [README](../README.md)) and ```host index``` is a number which identifies a host on which each individual file is created among all hosts. 

### Writing a file

To write a file, you can do

```
    APPEND=README.md TO="/path/to/store-1" bredfs write
```

The content of ```README.md``` will be added to a virtual file ```/path/to/store-1```.

### Reading a file

Reading a file is a bit more complecated part than the others.
Just to read it, you can do

```
    FROM=/path/to/store-1 bredfs read
```

If you want to filter lines from the file, you can do following for instance

```
    FROM=/path/to/store-1 WHERE="grep -E 'A|HELLO'" bredfs read
```

This will print lines containing ```A``` or ```HELLO``` in a virtual file ```/path/to/store-1```.

Also you can pick up column(s) from each line by a following command line.

```
    SELECT="cut -f 2 -d ' '" WHERE="grep 'HELLO'" FROM="/path/to/store-1" bredfs read
```

This will print *first* column from the left in lines which contain "HELLO".
That is, if content of ```/path/to/store-1``` is as following,

```

    howdy HELLO
	mundus World

```

then printed will be

```
    howdy
```

And you may already notice the command passed to ```bredfs``` to pick up certain column is,

```
    cut -f 2 -d ' '
```

This should print *second* column not the *first* column.
Why can this happen?

It is because ```bredfs``` appends an id to each line of the input file when it is stored.
This means the file above will be splitted and stored in two files as follows

```file 1```

```

    1 howdy HELLO

```

```file 2```

```

    2 mundus World

```

And the left most column will be stripped on ```bredfs read``` automatically.
This is why you need to ```+1``` to access intended data when you use ```cut``` command in ```SELECT```.
More generatilly, of course, you need take this behavior into consideration when using ```SELECT``` and access one next right columns to get appropriate data.

## Classic examples
Followings are the examples from original ```br```

### sorting

```
bred < input > output
```

### word count

```
bred -r "uniq -c" < input > output
```

### great big join

```
LC_ALL='C' bred -r "join - /tmp/join_data" < input > output
```

# Performance
## map mode and reduce more
(not yet done)
Since I'm planning 2 major improvements which impact ```map``` and ```reduce``` modes, I have not yet started
performance testing.

## compatibility mode
This section is a work done by erikfrey and cited from [bashreduce's README](https://github.com/erikfrey/bashreduce/blob/master/README.textile).

### big honkin' local machine

Let's start with a simpler scenario: I have a machine with multiple cores and with normal unix tools I'm relegated to using just one core.  How does br help us here?  Here's br on an 8-core machine, essentially operating as a poor man's multi-core sort:


| command                                    | using     | time       | rate      |
|:-------------------------------------------|-----------|-----------:|----------:|
| sort -k1,1 -S2G 4gb_file > 4gb_file_sorted | coreutils | 30m32.078s | 2.24 MBps |
| br -i 4gb_file -o 4gb_file_sorted          | coreutils | 11m3.111s  | 6.18 MBps |
| br -i 4gb_file -o 4gb_file_sorted          | brp/brm   | 7m13.695s  | 9.44 MBps |


The job completely i/o saturates, but still a reasonable gain!

### many cheap machines

Here lies the promise of mapreduce: rather than use my big honkin' machine, I have a bunch of cheaper machines lying around that I can distribute my work to.  How does br behave when I add four cheaper 4-core machines into the mix?

|   command                                  |   using   |   time      |   rate     |
|:-------------------------------------------|-----------|------------:|-----------:|
| sort -k1,1 -S2G 4gb_file > 4gb_file_sorted | coreutils | 30m32.078s  |  2.24 MBps |
| br -i 4gb_file -o 4gb_file_sorted          | coreutils |  8m30.652s  |  8.02 MBps |
| br -i 4gb_file -o 4gb_file_sorted          | brp/brm   |  4m 7.596s  | 16.54 MBps |


We have a new bottleneck: we're limited by how quickly we can partition/pump our dataset out to the nodes.  awk and sort begin to show their limitations (our clever awk script is a bit cpu bound, and @sort -m@ can only merge so many files at once).  So we use two little helper programs written in C (yes, I know!  it's cheating!  if you can think of a better partition/merge using core unix tools, contact me) to partition the data and merge it back.

# Future work

* [Error handling improvement]()
* [Directory listing support]()
* [Implement better data exchange mechanism #3](https://github.com/dakusui/bred/issues/3)

# Notes
## About ```brp```'s behaviors
brp and the small awk script which dispatches rows basically do the same thing.
Both pick up a specified column, compute ```flvhash```, and dispatch the row to one of
output files.
But there are differences to be noticed.

1. ```brp``` detects column separator using ```isspace(3)```, which returns ```true```
   for " ". "\t", "\r", "\n", "\f", and "\v".
2. If ```brp``` finds  a character which makes ```isspace``` true, it immediately
   considers a field separator. Even if the row starts with those characters, or even
   if multiple white space characters are next to each other.

For example, perhaps the command line below is a bad practice.

```
    cat -n infile | br ...
```

Because ```cat -n``` produces results below,

```
___221	# Notes
___222	* About ```brp```'s behaviors
___223	brp and the small awk script which dispatches rows basically do the same thing.
___224	Both pick up a specified column, compute ```flvhash```, and dispatch the row to one of
```
(leading spaces are replaced with underlines)

Due to the ```brp```'s behavior described above, all the rows will be processed by the same worker since ```brp```
picks up a string of length 0 as the first field and compute a hash for it always.
Please use something like below instead.

```
    nl -w 1 -s ' ' -b a
```

# Authors
* Erik Frey <erik@fawx.com>
* Daniel Alex Finkelstein
* Zhou Zheng Sheng <edwardbadboy@qq.com>
* Hiroshi Ukai <dakusui@gmail.com>

# See also
* https://github.com/erikfrey/bashreduce
* https://github.com/danfinkelstein/bashreduce
* https://github.com/edwardbadboy
* https://github.com/dakusui/bred
